<!DOCTYPE html>
<html lang="fr">

<head>
      <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="canonical" href="http://danc.github.io/notes-hadoop.html" />

    <title>  Don't Panic &mdash; Notes hadoop
</title>




    <link rel="stylesheet" href="http://danc.github.io/theme/css/style.css">

    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->


    <meta name="author" content="Daniel">
    <meta name="description" content="! Les slides sont plus complètes (work in progress) Hadoop : bases Une explication par le projet Apache lui même : Je retiens de diverses lectures 2 ( ou 3) grands volets : Le stockage des données, distribué, scalable. Hadoop et ses diverses distributions Cloudera, Hortonworks, Mapr en restent la principale brique, qui semble un ...">
  <meta name="tags" contents="hadoop, bigdata, ">
</head>

<body>
<header class="header">
  <div class="container">
    <div class="header-inner">
      <h1 class="header-name">
        <a class="nodec" href="http://danc.github.io">Don't Panic</a>
      </h1>
      <h3 class="header-text"></h3>
      <ul class="header-menu list-inline">
          <li><a class="nodec icon-github" href="https://github.com/danc"></a></li>
          <li><a class="nodec icon-twitter" href="https://twitter.com/tintouli"></a></li>
      </ul>
    </div>
  </div>
</header> <!-- /.header -->  <div class="container">
  <div class="post full-post">
    <h1 class="post-title">
      <a href="/notes-hadoop.html" title="Permalink to Notes hadoop">Notes hadoop</a>
    </h1>
    <ul class="list-inline">
      <li class="post-date">
        <a class="text-muted" href="/notes-hadoop.html" title="2015-02-24T00:00:00+01:00">mar. 24 février 2015</a>
      </li>
      <li class="muted">&middot;</li>
      <li class="post-category">
        <a href="http://danc.github.io/category/misc.html">misc</a>
      </li>
        <li class="muted">&middot;</li>
        <li>
            <a href="http://danc.github.io/tag/hadoop.html">hadoop</a>,             <a href="http://danc.github.io/tag/bigdata.html">bigdata</a>        </li>
    </ul>
    <div class="post-content">
      <p>! Les <a href="/slide/bigdata/2015-02-24-hadoop.html">slides</a> sont plus complètes  (work in progress)</p>
<h1>Hadoop : bases</h1>
<p>Une explication par le <a href="http://hadoop.apache.org/#What+Is+Apache+Hadoop%3F">projet Apache</a> lui même :</p>
<p>Je retiens de diverses lectures 2 ( ou 3) grands volets :</p>
<ul>
<li><strong>Le stockage des données, distribué, scalable</strong>. </li>
</ul>
<p>Hadoop et ses diverses distributions Cloudera, Hortonworks, Mapr en restent la principale brique, qui semble un socle commun à plein de solutions</p>
<p>Note : dans certains cas de traitements temps réel sans besoin de stockage, on peut s'affranchir d'hadoop</p>
<ul>
<li><strong>Le traitement des données, parallélisable</strong></li>
</ul>
<p>Principalement basés sur un stockage des données hadoop, des tas de librairies (Mahout), algorithmes(MapReduce, Spark, ) , gestionnaires (Ambari, Zookeeper) , infrastructures et langages (Hive, Pig, Tez, HBase, Cassandra, Storm).... permettent de paralléliser des traitements de données.</p>
<p>C'est là qu'il y a une grosse ébullition, beaucoup de technlogies proposées, et qu'il y a besoin d'y voir plus clair (Quelle technologie utiliser pour quelle problématique ?).</p>
<p>La maitrise de toutes ces technologies pose question aussi, et je vois un outil comme Talend comme une manière de pouvoir adresser ces technologies de manière homogène, au moins dans les grosses mailles (dans le détail, il y a peut-être des limitations à utiliser une sur-couche comme Talend)</p>
<ul>
<li><strong>La visualisation et la restitution des données</strong></li>
</ul>
<p>C'est le troisième point qui est souvent délaissé, mais qui semble évident pour le client : il veut pouvoir manipuler ses données et les rendre lisibles, si possible de manière interactive et par des non experts, qui ne savent pas forcément au départ ce qu'ils sont venus chercher dans ses méga-données.</p>
<h1>Notes diverses :</h1>
<p><a href="http://hugfrance.fr/presentation-de-spark-par-tugdual-sarazin/">source</a></p>
<p><strong>Spark</strong> : permet de s'affranchir de hadoop/Yarn, fonctionne directement sur Apache Mesos, EC2, ...</p>
<p><strong>Shark</strong> : Hive pour Spark (compatible, plus rapide)</p>
<p><a href="http://mahout.apache.org/">source</a></p>
<p><strong>Mahout : 25 April 2014 - Goodbye MapReduce</strong> :</p>
<p>Les algorithmes Mahout en MapReduce seront remplacés progressivement par des algos en Spark (au delà de la v0.9, donc)</p>
    </div>
  </div>
  <hr class="separator">
  <div class="col-md-8 col-md-offset-2">
  </div>
  </div>
<footer class="footer">
  <div class="container">
    <p class="text-center">
      Daniel, <a href="" target="_blank"></a> unless otherwise noted.
    </p>
    <div class="text-center">
      Generated by <a href="http://getpelican.com" target="_blank">Pelican</a> with the <a href="http://github.com/nairobilug/pelican-alchemy">alchemy</a> theme.
    </div>
  </div>
</footer> <!-- /.footer -->
  <script src="http://danc.github.io/theme/js/jquery.min.js"></script>
  <script src="http://danc.github.io/theme/js/bootstrap.min.js"></script>
</body> <!-- 42 -->

</html>